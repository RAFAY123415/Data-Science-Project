{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca2781fc",
   "metadata": {},
   "source": [
    "##### We will apply bert model for amazon reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed61926",
   "metadata": {},
   "source": [
    "##### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_file.xlsx' with the path to your Excel file\n",
    "file_path = 'Amazon Reviews Validation Data.xlsx'\n",
    "\n",
    "# Read the Excel file into a Pandas DataFrame\n",
    "try:\n",
    "    Amazon_Reviews_validation = pd.read_excel(file_path)\n",
    "    # Print the first 5 rows of the DataFrame for verification\n",
    "except FileNotFoundError:\n",
    "    print(f\"File '{file_path}' not found.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"Error occurred while parsing the Excel file '{file_path}'. Please check the file format and structure.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon_Reviews_Training=pd.read_csv('Amazon_Synthetic_Training_Data.csv')\n",
    "Amazon_Reviews_validation = Amazon_Reviews_validation.drop_duplicates(subset=['Reviews'])\n",
    "Amazon_Reviews_validation.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630d81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_training_data=Amazon_Reviews_Training\n",
    "amazon_validation_data=Amazon_Reviews_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_training_data = amazon_training_data.rename(columns={'Reviews': 'Comment_Text', 'Aspect': 'Label'})\n",
    "amazon_validation_data = amazon_validation_data.rename(columns={'Reviews': 'Comment_Text', 'Aspect': 'Label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142eed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = [\n",
    "    'Adaptability', 'Durability', 'Ease of Use', 'Ergonomics',\n",
    "    'Interference', 'Performance', 'Use Efficiency', 'Aesthetics',\n",
    "    'Ease of Reprocessing', 'Ease of Storage', 'Price', 'Safety'\n",
    "]\n",
    "\n",
    "# Map labels to numerical values (0 to 12)\n",
    "labeling_dict = {label: idx for idx, label in enumerate(original_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_training_data['Label']=amazon_training_data['Label'].map(labeling_dict)\n",
    "amazon_validation_data['Label']=amazon_validation_data['Label'].map(labeling_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2b2fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =amazon_training_data[\"Comment_Text\"].to_list()\n",
    "X_val=amazon_validation_data[\"Comment_Text\"].to_list()\n",
    "y_train = amazon_training_data[\"Label\"].to_list()\n",
    "y_val=amazon_validation_data[\"Label\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad2940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
    "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d33b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e53ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dfabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63808dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=50\n",
    "\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dec213",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_validation_metrics=trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c5099",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss=Model_validation_metrics['eval_loss']\n",
    "Accuracy=Model_validation_metrics['eval_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd22cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Validation_Loss is : {Loss}, and Validation_Accuracy is : {Accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('CustomModel')\n",
    "tokenizer.save_pretrained('Tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d913cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('Tokenizer')\n",
    "model = BertForSequenceClassification.from_pretrained(\"CustomModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9954f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(\"Input for single value for multiple we will run for loop\", return_tensors='pt',padding=True,truncation=True)\n",
    "output = model(**encoded_input)\n",
    "logits = output.logits.detach().cpu().numpy()\n",
    "y_pred = np.argmax(logits,axis=-1)\n",
    "given_value =y_pred[0]\n",
    "# Get the key for the given value\n",
    "result_key = next(key for key, value in labeling_dict.items() if value == given_value)\n",
    "# Print the result\n",
    "print(result_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

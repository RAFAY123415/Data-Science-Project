{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWKRr54xUO_T",
        "outputId": "2de8f3e2-14b4-4063-defe-897c7851b238"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/225.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/225.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.6.1 typing-extensions-4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We can create a speech from the given input and store at some place"
      ],
      "metadata": {
        "id": "wIhUIyoXXQB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-zGrS5AWIJNO"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import openai\n",
        "\n",
        "# Define the path where the generated speech file will be saved\n",
        "script_directory = Path.cwd()\n",
        "speech_file_path = script_directory / \"speech.mp3\"\n",
        "\n",
        "# Make a request to the OpenAI Audio API to generate speech\n",
        "response = openai.audio.speech.create(\n",
        "    model=\"tts-1\",   # The latest text to speech model, optimized for speed.\n",
        "    voice=\"alloy\",   # The voice style for the generated speech\n",
        "    input=\"The quick brown fox jumped over the lazy dog.\"   # The text to be converted to speech\n",
        ")\n",
        "\n",
        "# Save the generated speech to the specified file path\n",
        "response.stream_to_file(speech_file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We can also convert into hd format"
      ],
      "metadata": {
        "id": "R33fUZO5fYVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import openai\n",
        "\n",
        "# Define the path where the generated speech file will be saved\n",
        "script_directory = Path.cwd()\n",
        "speech_file_path = script_directory / \"speech.mp3\"\n",
        "\n",
        "# Make a request to the OpenAI Audio API to generate speech\n",
        "response = openai.audio.speech.create(\n",
        "    model=\"tts-1-hd\",   # The latest text to speech model, optimized for quality.\n",
        "    voice=\"alloy\",   # The voice style for the generated speech\n",
        "    input=\"The quick brown fox jumped over the lazy dog.\"   # The text to be converted to speech\n",
        ")\n",
        "\n",
        "# Save the generated speech to the specified file path\n",
        "response.stream_to_file(speech_file_path)"
      ],
      "metadata": {
        "id": "OgfNwqj6fWbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Converting Speech into Text transcriptions means (that you have to send speech file and then you should b convert into any language )"
      ],
      "metadata": {
        "id": "PW3IzPk4X4f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "audio_file = open(\"speech.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=audio_file\n",
        ")\n"
      ],
      "metadata": {
        "id": "WQbKB1CkXylc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting Speech to text using translation (means that you have to only convert translate speech into english)"
      ],
      "metadata": {
        "id": "vT7ZVl3ectFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "audio_file = open(\"speech.mp3\", \"rb\")\n",
        "transcript = client.audio.translations.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=audio_file\n",
        ")\n"
      ],
      "metadata": {
        "id": "v1cxORsxcw_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Function is taking audio file in hindi and converting it into english called translation function\n",
        "\n",
        "### The Second Function is taking hindi audio file and convert into hindi text by defualt we can also pass another language instead of generating text in hindi"
      ],
      "metadata": {
        "id": "mzkuBJvo6kw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file = open(\"/content/different_language.mp3\", \"rb\")\n",
        "translated_transcript = client.audio.translations.create(\n",
        "    model=\"whisper-1\",\n",
        "    response_format = \"text\",\n",
        "    file=audio_file\n",
        ")\n",
        "print(\"Translated Transcript: \", translated_transcript)\n",
        "\n",
        "original_transcript = client.audio.transcriptions.create(\n",
        "    model=\"whisper-1\",\n",
        "    response_format=\"text\",\n",
        "    file=audio_file\n",
        ")\n",
        "print(\"Original Transcript: \", original_transcript)\n"
      ],
      "metadata": {
        "id": "RwCXHZye11cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### So here is the problem how we can convert large files that are max of 25 mbs"
      ],
      "metadata": {
        "id": "G3o0OQXp1gEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### So we have a solution for that we can convert large files into small segments using python library called pydub"
      ],
      "metadata": {
        "id": "4YQwaZ_A13Pa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segmenting Audio for Efficient Processing\n",
        "\n",
        "When dealing with lengthy audio files, it's often necessary to segment them for easier processing. PyDub, a flexible audio processing library in Python, is an excellent tool for this task.\n",
        "\n",
        "Installing and Using PyDub\n",
        "\n",
        "Start by installing PyDub:"
      ],
      "metadata": {
        "id": "ypsxtT7o9yG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub -q"
      ],
      "metadata": {
        "id": "6--SdgbF9PV6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "# Load the audio file\n",
        "song = AudioSegment.from_mp3(\"/content/NLP Roadmap 2024 Step-by-Step Guide Resources.mp3\")\n",
        "\n",
        "# PyDub handles time in milliseconds\n",
        "five_minutes = 5 * 60 * 1000\n",
        "\n",
        "# Extract the first 5 minutes\n",
        "first_5_minutes = song[:five_minutes]\n",
        "\n",
        "# Export the segment\n",
        "first_5_minutes.export(\"split_speech.mp3\", format=\"mp3\")\n"
      ],
      "metadata": {
        "id": "EQlx6j3e93Y7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using the Segmented Audio with Whisper\n",
        "\n",
        "#With the segmented audio file, we can now efficiently utilize Whisper for transcription:"
      ],
      "metadata": {
        "id": "fEgdeqDO-Lq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file = open(\"/content/split_speech.mp3\", \"rb\")\n"
      ],
      "metadata": {
        "id": "mr3h0TlV-Oh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segmenting audio files is a practical approach to handling long recordings, making them more manageable for transcription or other audio processing tasks. PyDub's simplicity and efficiency make it an ideal choice for such operations."
      ],
      "metadata": {
        "id": "nZmBQ0Mp-Uat"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correcting Transcriptions with GPT-4\n",
        "Enhancing Transcript Accuracy\n",
        "\n",
        "Transcription errors are common, especially with unique terms or accents. In this section, we demonstrate how to use GPT-4 to correct transcription errors, focusing on specialized terminology related to Data Science.\n",
        "\n",
        "The Process\n",
        "\n",
        "Transcribe Audio: First, we transcribe the audio file using the Whisper API:"
      ],
      "metadata": {
        "id": "Dyqmqwnq-bQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(audio_file):\n",
        "     transcript = client.audio.translations.create(\n",
        "         model=\"whisper-1\",\n",
        "         response_format=\"text\",\n",
        "         file=audio_file\n",
        "     )\n",
        "     return transcript"
      ],
      "metadata": {
        "id": "Lxlb58Q99_Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Up the Correction Prompt: Prepare a system prompt instructing GPT-4 to correct spelling mistakes and ensure proper case usage for specialized terms."
      ],
      "metadata": {
        "id": "musoB8Zs-tG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " system_prompt = \"\"\"You are given a video transcript with spelling mistakes...\n",
        " Rewrite transcript in the same format correcting spelling mistakes...\"\"\"\n"
      ],
      "metadata": {
        "id": "QXE6CevL-nrG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Corrected Transcript: Combine the transcription with GPT-4 to produce a corrected version:"
      ],
      "metadata": {
        "id": "u_SZYSbr-4zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_corrected_transcript(system_prompt, audio_file):\n",
        "     text = transcribe(audio_file)\n",
        "     response = client.chat.completions.create(\n",
        "         model=\"gpt-4\",\n",
        "         temperature=0,\n",
        "         messages=[\n",
        "             {\"role\": \"system\", \"content\": system_prompt},\n",
        "             {\"role\": \"user\", \"content\": text}\n",
        "         ]\n",
        "     )\n",
        "     return response.choices[0].message.content\n",
        "\n",
        " audio_file = open(\"/content/split_speech.mp3\", \"rb\")\n",
        " corrected_text = generate_corrected_transcript(system_prompt, audio_file)\n",
        " print(corrected_text)"
      ],
      "metadata": {
        "id": "UNLCd_ds-5kF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}